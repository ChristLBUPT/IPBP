{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explaination_baselines import get_possible_num_chunks, formalize_pickle_file_name\n",
    "import torch\n",
    "from torch import nn, Tensor, tensor\n",
    "from tqdm import trange\n",
    "import os.path as osp\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "KDE_SAVE_PTH = '/home/user/pretrained-models/kde/open_llama_7b/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading attention samples and calculating mean values...:   0%|                                                                                                                          | 0/39 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# assert set([len(each) for each in mean_values]) == 1, f'error, found different number of labels in different chunks: {set([len(each) for each in mean_values])}'\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_values, num_samples\n\u001b[0;32m---> 25\u001b[0m mean_values, num_samples \u001b[38;5;241m=\u001b[39m \u001b[43mprobeless_step1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKDE_SAVE_PTH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 17\u001b[0m, in \u001b[0;36mprobeless_step1\u001b[0;34m(train_data_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m             mean_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(label_features\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     16\u001b[0m         num_samples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(label_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m     mean_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mthis_neg_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m     num_samples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(this_neg_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# assert set([len(each) for each in mean_values]) == 1, f'error, found different number of labels in different chunks: {set([len(each) for each in mean_values])}'\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def probeless_step1(\n",
    "    train_data_dir: str,\n",
    "):\n",
    "    total_num_chunks = get_possible_num_chunks(train_data_dir)\n",
    "    mean_values, num_samples = [], []\n",
    "    for current_num_save in trange(total_num_chunks, desc='loading attention samples and calculating mean values...'):\n",
    "        this_neg_features: Tensor = torch.load(osp.join(train_data_dir, formalize_pickle_file_name('neg_attn_samples.pkl', 1, False, current_num_save, total_num_chunks)), map_location='cpu')\n",
    "        this_label_features: Tuple[Tensor] = torch.load(osp.join(train_data_dir, formalize_pickle_file_name('label_attn_samples.pkl', 1, False, current_num_save, total_num_chunks)), map_location='cpu')\n",
    "        mean_values.append([]) # [label1_batch1_mean_values(Tensor[n_features]), label2_batch1_mean_values(Tensor[n_features]), ... neg_batch1_mean_values(Tensor[n_features])]\n",
    "        num_samples.append([]) # [label1_batch1_n_samples(int), label2_batch1_n_samples(int), ... neg_batch1_n_samples(int)]\n",
    "        for label_features in this_label_features:\n",
    "            if label_features.shape[0] == 0:\n",
    "                mean_values[-1].append(torch.zeros(label_features.shape[-1]))\n",
    "            else:\n",
    "                mean_values[-1].append(label_features.mean(dim=0))\n",
    "            num_samples[-1].append(label_features.shape[0])\n",
    "        mean_values[-1].append(this_neg_features.mean(dim=0))\n",
    "        num_samples[-1].append(this_neg_features.shape[0])\n",
    "    \n",
    "    # assert set([len(each) for each in mean_values]) == 1, f'error, found different number of labels in different chunks: {set([len(each) for each in mean_values])}'\n",
    "    \n",
    "    return mean_values, num_samples\n",
    "\n",
    "    \n",
    "mean_values, num_samples = probeless_step1(KDE_SAVE_PTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probeless_step2(\n",
    "    mean_values: List[List[Tensor]], num_samples: List[List[int]]\n",
    "):\n",
    "    assert len(possible_num_labels := set([len(each) for each in mean_values])) == 1, f'error, different number of labels in different chunks: {possible_num_labels}'\n",
    "    assert len(possible_num_features := set([each.shape[-1] for _ in mean_values for each in _])) == 1, f'error, different number of features in different chunks: {possible_num_features}'\n",
    "    num_labels = list(possible_num_labels)[0]\n",
    "    num_features = list(possible_num_features)[0]\n",
    "    num_chunks = len(mean_values)\n",
    "    total_mean_values = torch.zeros(num_labels, num_features)\n",
    "    total_num_samples = torch.Tensor(num_samples).sum(dim=0).tolist()\n",
    "    for this_mean_values, this_num_samples in zip(mean_values, num_samples): # iterate over chunks\n",
    "        for label_idx in range(num_labels):\n",
    "            if total_num_samples[label_idx] != 0:\n",
    "                total_mean_values[label_idx] += this_mean_values[label_idx] * (this_num_samples[label_idx] / total_num_samples[label_idx])\n",
    "            # total_mean_values.append(this_mean_values)\n",
    "\n",
    "    return total_mean_values\n",
    "\n",
    "total_mean_values = probeless_step2(mean_values, num_samples) # total_mean_values = Tensor[n_labels, n_features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(total_mean_values, osp.join(KDE_SAVE_PTH, 'baselines', 'total_mean_values.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = total_mean_values.shape[0]\n",
    "pl_matrix = torch.zeros_like(total_mean_values)\n",
    "\n",
    "for z in range(num_labels):\n",
    "    for z2 in range(num_labels):\n",
    "        pl_matrix[z] += (total_mean_values[z2] - total_mean_values[z]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0614, 12.9103, 13.9199,  ..., 48.1243,  4.3099, 40.9697],\n",
      "        [ 6.2106,  3.9450,  4.4875,  ...,  9.6447,  3.3624,  6.7478],\n",
      "        [ 3.0707,  3.4532,  4.1131,  ..., 14.7476,  5.0805,  9.8415],\n",
      "        ...,\n",
      "        [ 3.1218,  3.3797,  4.0568,  ..., 15.3775,  5.7540, 12.2089],\n",
      "        [12.0614, 12.9103, 13.9199,  ..., 48.1243,  4.3099, 40.9697],\n",
      "        [ 3.7964,  3.2735,  4.2227,  ..., 20.1973,  6.1718, 16.6401]])\n"
     ]
    }
   ],
   "source": [
    "print(pl_matrix)\n",
    "torch.save(pl_matrix, osp.join(KDE_SAVE_PTH, 'baselines', 'total_mean_values.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(2, 5).float()\n",
    "a.quantile(0.5, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading attention samples and calculating iou_matrix...:  59%|███████████████████████████████████████████████████████████████████▏                                              | 23/39 [35:41<25:21, 95.11s/it]"
     ]
    }
   ],
   "source": [
    "def iou(train_data_dir: str, threshold: float = 0.5, dynamic_threshold: bool = False, dynamic_threshold_percentile: float = 0.995):\n",
    "    total_num_chunks = get_possible_num_chunks(train_data_dir)\n",
    "    num_labels = -1\n",
    "    num_features = -1\n",
    "    iou_intersection, iou_union = None, None\n",
    "    for current_num_save in trange(total_num_chunks, desc='loading attention samples and calculating iou_matrix...'):\n",
    "        # load neg and label features and dynamically calculate the number of labels and features, while assuring the number of features is consistent across all chunks\n",
    "        neg_features: Tensor = torch.load(osp.join(train_data_dir, formalize_pickle_file_name('neg_attn_samples.pkl', 1, False, current_num_save, total_num_chunks)), map_location='cpu')\n",
    "        label_features: Tuple[Tensor] = torch.load(osp.join(train_data_dir, formalize_pickle_file_name('label_attn_samples.pkl', 1, False, current_num_save, total_num_chunks)), map_location='cpu')\n",
    "        if num_labels == -1:\n",
    "            num_labels = len(label_features) + 1\n",
    "        else:\n",
    "            assert num_labels == len(label_features) + 1, f'error, different number of labels in different chunks: {num_labels} vs {len(label_features) + 1}'\n",
    "        assert len(set([each.shape[-1] for each in label_features + (neg_features,)])) == 1, f'error, different number of features in different chunks: {set([each.shape[-1] for each in label_features + (neg_features,)])}'\n",
    "        if num_features == -1:\n",
    "            num_features = neg_features.shape[-1]\n",
    "        else:\n",
    "            assert num_features == neg_features.shape[-1], f'error, different number of features in different chunks: {num_features} vs {neg_features.shape[-1]}'\n",
    "        if iou_intersection is None: iou_intersection = torch.zeros(num_labels, num_features)\n",
    "        if iou_union is None: iou_union = torch.zeros(num_labels, num_features)\n",
    "        label_features = label_features + (neg_features,) # concatenate neg features at the tail of label features\n",
    "        if dynamic_threshold:\n",
    "            threshold = torch.cat(label_features, dim=0).float().quantile(dynamic_threshold_percentile, dim=0, keepdim=True) # [num_features]\n",
    "        for label_idx in range(num_labels):\n",
    "            this_label_features = label_features[label_idx]\n",
    "            if this_label_features.shape[0] != 0:\n",
    "                high_value_mask = (this_label_features > threshold).long() # [num_samples, num_features]\n",
    "                feature_high_values = high_value_mask.sum(dim=0) # [num_features]\n",
    "                iou_intersection[label_idx] += feature_high_values\n",
    "                feature_num_samples = torch.ones(num_features) * this_label_features.shape[0] # [num_features]\n",
    "                for other_label_idx in range(num_labels):\n",
    "                    if other_label_idx == label_idx:\n",
    "                        iou_union[other_label_idx] += feature_num_samples # for this label, add the number of samples to each feature's entry in the matrix (since the `feature mask` is all 1)\n",
    "                    else:\n",
    "                        iou_union[other_label_idx] += feature_high_values # for other labels, add the number of high values to each feature's entry in the matrix\n",
    "    \n",
    "    return iou_intersection / iou_union\n",
    "\n",
    "iou_matrix = iou(KDE_SAVE_PTH, dynamic_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.8358e-03, 8.9633e-03, 0.0000e+00,  ..., 4.0604e-05, 1.5527e-05,\n",
      "         9.0804e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 6.8045e-05,  ..., 5.5433e-03, 5.8366e-05,\n",
      "         2.2208e-02],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [4.8371e-03, 4.8854e-03, 4.7513e-03,  ..., 4.6057e-03, 4.9403e-03,\n",
      "         4.2393e-03]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(iou_matrix, osp.join(KDE_SAVE_PTH, 'baselines', 'iou_matrix_dynamic_0.995.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou1 = torch.load(osp.join(KDE_SAVE_PTH, 'baselines', 'iou_matrix_dynamic_0.995.pt'))\n",
    "iou2 = torch.load(osp.join(KDE_SAVE_PTH, 'baselines', 'iou_matrix_static_0.5.pt'))\n",
    "print(iou1)\n",
    "print(iou2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
